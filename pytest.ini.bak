# Pytest configuration for WASM Shim for Torch
# Centralizes test configuration and settings

[tool:pytest]
# Minimum pytest version
minversion = 7.0

# Test discovery patterns
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

# Test paths
testpaths = tests

# Default command line options
addopts = 
    # Coverage options
    --cov=wasm_torch
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-report=xml:coverage.xml
    --cov-branch
    
    # Output options
    --tb=short
    --strict-markers
    --strict-config
    --verbose
    
    # Performance options
    --durations=10
    
    # Plugin options
    --benchmark-skip
    
    # Warnings
    -W ignore::DeprecationWarning
    -W ignore::PendingDeprecationWarning

# Test markers for categorization
markers =
    # Performance and timing
    slow: marks tests as slow (deselect with '-m "not slow"')
    benchmark: marks tests as benchmarks (use --benchmark-only to run)
    
    # Test categories
    unit: unit tests that test individual functions/classes
    integration: integration tests that test component interactions
    e2e: end-to-end tests that test complete workflows
    
    # Feature areas
    export: tests related to model export functionality
    runtime: tests related to WASM runtime
    cli: tests related to command-line interface
    optimization: tests related to model optimization
    
    # Platform specific
    wasm: tests that require WASM runtime (may need special setup)
    gpu: tests that require GPU support
    browser: tests that require browser environment
    
    # External dependencies
    torch: tests that require PyTorch
    emscripten: tests that require Emscripten toolchain
    network: tests that require network access
    
    # Test quality
    flaky: tests that are known to be flaky
    skip: tests that should be skipped
    xfail: tests that are expected to fail

# Pytest plugins
required_plugins =
    pytest-cov>=4.1.0
    pytest-benchmark>=4.0.1
    pytest-xdist>=3.3.0
    pytest-mock>=3.11.0

# Logging configuration
log_cli = false
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = tests.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(filename)s:%(lineno)d - %(funcName)s(): %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# Test timeout (in seconds)
timeout = 300

# Parallel testing with pytest-xdist
# Use with: pytest -n auto
# Maximum number of workers
max_worker_restart = 3

# Filter warnings
filterwarnings =
    # Ignore specific deprecation warnings from dependencies
    ignore::DeprecationWarning:torch.*
    ignore::UserWarning:torch.*
    ignore::FutureWarning:numpy.*
    
    # Convert certain warnings to errors
    error::UserWarning:wasm_torch.*
    
    # Ignore warnings from test dependencies
    ignore::pytest.PytestUnraisableExceptionWarning

# Environment variables for tests
env = 
    # Set deterministic behavior
    PYTHONHASHSEED = 0
    
    # Disable GPU for consistent testing
    CUDA_VISIBLE_DEVICES = ""
    
    # Test-specific settings
    WASM_TORCH_TEST_MODE = 1
    WASM_TORCH_DEBUG = 0
    
    # Disable analytics/telemetry during testing
    DO_NOT_TRACK = 1

# Test collection configuration
collect_ignore = [
    "setup.py",
    "build",
    "dist",
    ".tox",
    ".eggs",
    "docs/_build",
]

# Doctest configuration
doctest_optionflags = NORMALIZE_WHITESPACE IGNORE_EXCEPTION_DETAIL ELLIPSIS

# Console output configuration
console_output_style = progress

# Temporary directory configuration
tmp_path_retention_count = 3
tmp_path_retention_policy = "failed"