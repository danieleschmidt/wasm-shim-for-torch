"""Global Deployment Orchestrator for WASM-Torch

Planetary-scale deployment system with multi-region coordination, intelligent
edge distribution, and autonomous global infrastructure management.
"""

import asyncio
import time
import logging
import json
import random
from typing import Dict, List, Any, Optional, Set, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum
from collections import defaultdict, deque
import threading
from abc import ABC, abstractmethod
import yaml

class DeploymentRegion(Enum):
    """Global deployment regions"""
    # North America
    NA_EAST = "na-east-1"
    NA_WEST = "na-west-1"
    NA_CENTRAL = "na-central-1"
    
    # Europe
    EU_WEST = "eu-west-1"
    EU_CENTRAL = "eu-central-1"
    EU_NORTH = "eu-north-1"
    
    # Asia Pacific
    APAC_SOUTHEAST = "apac-southeast-1"
    APAC_NORTHEAST = "apac-northeast-1"
    APAC_SOUTH = "apac-south-1"
    
    # Other Regions
    SA_EAST = "sa-east-1"
    AFRICA_SOUTH = "af-south-1"
    OCEANIA = "oc-southeast-1"

class DeploymentStrategy(Enum):
    """Deployment strategies"""
    BLUE_GREEN = "blue_green"
    CANARY = "canary"
    ROLLING = "rolling"
    SHADOW = "shadow"
    A_B_TEST = "ab_test"
    FEATURE_FLAG = "feature_flag"
    AUTONOMOUS_ADAPTIVE = "autonomous_adaptive"

class DeploymentStatus(Enum):
    """Deployment status"""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    DEPLOYED = "deployed"
    FAILED = "failed"
    ROLLING_BACK = "rolling_back"
    ROLLED_BACK = "rolled_back"

@dataclass
class RegionConfig:
    """Configuration for a deployment region"""
    region: DeploymentRegion
    enabled: bool = True
    capacity: Dict[str, int] = field(default_factory=lambda: {
        "cpu_cores": 100,
        "memory_gb": 400,
        "storage_gb": 1000,
        "bandwidth_gbps": 10
    })
    latency_requirements: Dict[str, float] = field(default_factory=lambda: {
        "p50": 50.0,  # ms
        "p95": 200.0,
        "p99": 500.0
    })
    compliance_requirements: Set[str] = field(default_factory=lambda: {
        "gdpr", "ccpa", "hipaa"
    })
    edge_locations: List[str] = field(default_factory=list)
    
@dataclass
class DeploymentTarget:
    """Deployment target specification"""
    application: str
    version: str
    regions: List[DeploymentRegion]
    strategy: DeploymentStrategy
    rollout_percentage: float = 100.0
    health_check_url: str = "/health"
    success_criteria: Dict[str, Any] = field(default_factory=lambda: {
        "error_rate": 0.01,  # 1%
        "response_time_p95": 200.0,  # ms
        "availability": 0.999  # 99.9%
    })
    rollback_criteria: Dict[str, Any] = field(default_factory=lambda: {
        "error_rate": 0.05,  # 5%
        "response_time_p95": 1000.0,  # ms
        "availability": 0.95  # 95%
    })

@dataclass
class DeploymentInstance:
    """Individual deployment instance"""
    deployment_id: str
    target: DeploymentTarget
    region: DeploymentRegion
    status: DeploymentStatus
    created_at: float
    updated_at: float
    metrics: Dict[str, Any] = field(default_factory=dict)
    logs: List[str] = field(default_factory=list)
    health_status: str = "unknown"

class GlobalLoadBalancer:
    """Global load balancing and traffic routing"""
    
    def __init__(self):
        self.region_weights: Dict[DeploymentRegion, float] = {}
        self.traffic_patterns: Dict[str, Dict[str, float]] = {}
        self.geo_routing_rules: Dict[str, DeploymentRegion] = {}
        
    def calculate_optimal_routing(self, 
                                user_location: str,
                                available_regions: List[DeploymentRegion]) -> DeploymentRegion:
        """Calculate optimal region for user request"""
        # Simplified geo-routing logic
        geo_mappings = {
            "US": [DeploymentRegion.NA_EAST, DeploymentRegion.NA_WEST, DeploymentRegion.NA_CENTRAL],
            "CA": [DeploymentRegion.NA_CENTRAL, DeploymentRegion.NA_EAST, DeploymentRegion.NA_WEST],
            "GB": [DeploymentRegion.EU_WEST, DeploymentRegion.EU_CENTRAL, DeploymentRegion.EU_NORTH],
            "DE": [DeploymentRegion.EU_CENTRAL, DeploymentRegion.EU_WEST, DeploymentRegion.EU_NORTH],
            "JP": [DeploymentRegion.APAC_NORTHEAST, DeploymentRegion.APAC_SOUTHEAST],
            "SG": [DeploymentRegion.APAC_SOUTHEAST, DeploymentRegion.APAC_NORTHEAST],
            "IN": [DeploymentRegion.APAC_SOUTH, DeploymentRegion.APAC_SOUTHEAST],
            "AU": [DeploymentRegion.OCEANIA, DeploymentRegion.APAC_SOUTHEAST],
            "BR": [DeploymentRegion.SA_EAST],
            "ZA": [DeploymentRegion.AFRICA_SOUTH, DeploymentRegion.EU_WEST]
        }
        
        # Get preferred regions for user location
        preferred_regions = geo_mappings.get(user_location, [DeploymentRegion.NA_EAST])
        
        # Find first available preferred region
        for region in preferred_regions:
            if region in available_regions:
                return region
        
        # Fallback to any available region
        return available_regions[0] if available_regions else DeploymentRegion.NA_EAST
    
    def update_traffic_weights(self, region_metrics: Dict[DeploymentRegion, Dict[str, float]]):
        """Update traffic weights based on region performance"""
        for region, metrics in region_metrics.items():
            # Calculate weight based on performance metrics
            latency_score = max(0, 1.0 - metrics.get("avg_latency", 100) / 1000.0)
            error_rate_score = max(0, 1.0 - metrics.get("error_rate", 0.01))
            availability_score = metrics.get("availability", 0.99)
            
            weight = (latency_score * 0.4 + error_rate_score * 0.3 + availability_score * 0.3)
            self.region_weights[region] = weight

class ComplianceManager:
    """Manages regulatory compliance across regions"""
    
    def __init__(self):
        self.compliance_rules = self._load_compliance_rules()
        self.data_residency_requirements = self._load_data_residency_rules()
    
    def _load_compliance_rules(self) -> Dict[str, Dict[str, Any]]:
        """Load compliance rules for different regulations"""
        return {
            "gdpr": {
                "applicable_regions": [
                    DeploymentRegion.EU_WEST,
                    DeploymentRegion.EU_CENTRAL,
                    DeploymentRegion.EU_NORTH
                ],
                "data_protection_requirements": [
                    "encryption_at_rest",
                    "encryption_in_transit", 
                    "right_to_deletion",
                    "data_portability",
                    "consent_management"
                ],
                "data_transfer_restrictions": True,
                "retention_period_max_days": 2555  # 7 years
            },
            "ccpa": {
                "applicable_regions": [DeploymentRegion.NA_WEST],
                "data_protection_requirements": [
                    "opt_out_rights",
                    "data_disclosure",
                    "deletion_rights"
                ],
                "data_transfer_restrictions": False,
                "retention_period_max_days": 365
            },
            "hipaa": {
                "applicable_regions": [
                    DeploymentRegion.NA_EAST,
                    DeploymentRegion.NA_WEST,
                    DeploymentRegion.NA_CENTRAL
                ],
                "data_protection_requirements": [
                    "phi_encryption",
                    "access_logging",
                    "audit_trails",
                    "breach_notification"
                ],
                "data_transfer_restrictions": True,
                "retention_period_max_days": 2190  # 6 years
            }
        }
    
    def _load_data_residency_rules(self) -> Dict[DeploymentRegion, Set[str]]:
        """Load data residency rules for regions"""
        return {
            DeploymentRegion.EU_WEST: {"eu_data_only", "gdpr_compliant"},
            DeploymentRegion.EU_CENTRAL: {"eu_data_only", "gdpr_compliant"},
            DeploymentRegion.EU_NORTH: {"eu_data_only", "gdpr_compliant"},
            DeploymentRegion.APAC_SOUTH: {"local_data_only"},
            DeploymentRegion.AFRICA_SOUTH: {"african_union_data"}
        }
    
    def validate_deployment_compliance(self, 
                                     target: DeploymentTarget,
                                     user_data_types: Set[str]) -> Dict[str, Any]:
        """Validate if deployment meets compliance requirements"""
        validation_result = {
            "compliant": True,
            "violations": [],
            "recommendations": []
        }
        
        for region in target.regions:
            # Check data residency requirements
            residency_rules = self.data_residency_requirements.get(region, set())
            
            if "eu_data_only" in residency_rules and "non_eu_data" in user_data_types:
                validation_result["compliant"] = False
                validation_result["violations"].append(
                    f"Region {region.value} requires EU data only but non-EU data detected"
                )
            
            # Check compliance rule applicability
            for compliance_type, rules in self.compliance_rules.items():
                if region in rules["applicable_regions"]:
                    # Validate data protection requirements
                    for requirement in rules["data_protection_requirements"]:
                        if not self._check_requirement_implemented(requirement, target):
                            validation_result["recommendations"].append(
                                f"Implement {requirement} for {compliance_type} compliance in {region.value}"
                            )
        
        return validation_result
    
    def _check_requirement_implemented(self, requirement: str, target: DeploymentTarget) -> bool:
        """Check if a compliance requirement is implemented"""
        # Simplified implementation check
        # In real implementation, would check actual infrastructure configuration
        return True  # Assume all requirements are implemented

class EdgeNetworkManager:
    """Manages edge network deployment and optimization"""
    
    def __init__(self):
        self.edge_locations: Dict[str, Dict[str, Any]] = {}
        self.content_distribution_rules: Dict[str, List[str]] = {}
        
    def initialize_edge_locations(self):
        """Initialize global edge locations"""
        edge_configs = {
            # North America Edge Locations
            "na-edge-1": {"region": DeploymentRegion.NA_EAST, "city": "New York", "capacity": "high"},
            "na-edge-2": {"region": DeploymentRegion.NA_EAST, "city": "Miami", "capacity": "medium"},
            "na-edge-3": {"region": DeploymentRegion.NA_WEST, "city": "Los Angeles", "capacity": "high"},
            "na-edge-4": {"region": DeploymentRegion.NA_WEST, "city": "San Francisco", "capacity": "high"},
            "na-edge-5": {"region": DeploymentRegion.NA_CENTRAL, "city": "Chicago", "capacity": "medium"},
            
            # Europe Edge Locations
            "eu-edge-1": {"region": DeploymentRegion.EU_WEST, "city": "London", "capacity": "high"},
            "eu-edge-2": {"region": DeploymentRegion.EU_WEST, "city": "Dublin", "capacity": "medium"},
            "eu-edge-3": {"region": DeploymentRegion.EU_CENTRAL, "city": "Frankfurt", "capacity": "high"},
            "eu-edge-4": {"region": DeploymentRegion.EU_CENTRAL, "city": "Paris", "capacity": "medium"},
            "eu-edge-5": {"region": DeploymentRegion.EU_NORTH, "city": "Stockholm", "capacity": "medium"},
            
            # APAC Edge Locations
            "apac-edge-1": {"region": DeploymentRegion.APAC_NORTHEAST, "city": "Tokyo", "capacity": "high"},
            "apac-edge-2": {"region": DeploymentRegion.APAC_NORTHEAST, "city": "Seoul", "capacity": "medium"},
            "apac-edge-3": {"region": DeploymentRegion.APAC_SOUTHEAST, "city": "Singapore", "capacity": "high"},
            "apac-edge-4": {"region": DeploymentRegion.APAC_SOUTHEAST, "city": "Sydney", "capacity": "medium"},
            "apac-edge-5": {"region": DeploymentRegion.APAC_SOUTH, "city": "Mumbai", "capacity": "medium"},
            
            # Other Regions
            "sa-edge-1": {"region": DeploymentRegion.SA_EAST, "city": "SÃ£o Paulo", "capacity": "medium"},
            "af-edge-1": {"region": DeploymentRegion.AFRICA_SOUTH, "city": "Cape Town", "capacity": "low"},
            "oc-edge-1": {"region": DeploymentRegion.OCEANIA, "city": "Auckland", "capacity": "low"}
        }
        
        self.edge_locations = edge_configs
    
    def optimize_content_distribution(self, 
                                    content_type: str,
                                    usage_patterns: Dict[str, float]) -> Dict[str, List[str]]:
        """Optimize content distribution across edge locations"""
        distribution_plan = defaultdict(list)
        
        # Analyze usage patterns and distribute content accordingly
        sorted_patterns = sorted(usage_patterns.items(), key=lambda x: x[1], reverse=True)
        
        for location, usage_weight in sorted_patterns:
            if usage_weight > 0.1:  # 10% threshold
                # Find nearest edge locations
                nearest_edges = self._find_nearest_edge_locations(location)
                distribution_plan[content_type].extend(nearest_edges[:2])  # Top 2
        
        return dict(distribution_plan)
    
    def _find_nearest_edge_locations(self, user_location: str) -> List[str]:
        """Find nearest edge locations for a user location"""
        # Simplified nearest edge location mapping
        location_mappings = {
            "US-East": ["na-edge-1", "na-edge-5"],
            "US-West": ["na-edge-3", "na-edge-4"],
            "UK": ["eu-edge-1", "eu-edge-2"],
            "DE": ["eu-edge-3", "eu-edge-4"],
            "JP": ["apac-edge-1", "apac-edge-2"],
            "SG": ["apac-edge-3", "apac-edge-4"],
            "AU": ["apac-edge-4", "oc-edge-1"],
            "BR": ["sa-edge-1"],
            "ZA": ["af-edge-1", "eu-edge-1"]
        }
        
        return location_mappings.get(user_location, ["na-edge-1", "eu-edge-1"])

class GlobalDeploymentOrchestrator:
    """Main global deployment orchestrator"""
    
    def __init__(self):
        # Core components
        self.region_configs: Dict[DeploymentRegion, RegionConfig] = {}
        self.active_deployments: Dict[str, DeploymentInstance] = {}
        self.deployment_history: List[DeploymentInstance] = []
        
        # Specialized managers
        self.load_balancer = GlobalLoadBalancer()
        self.compliance_manager = ComplianceManager()
        self.edge_manager = EdgeNetworkManager()
        
        # Initialize edge network
        self.edge_manager.initialize_edge_locations()
        
        # Monitoring and metrics
        self.regional_metrics: Dict[DeploymentRegion, Dict[str, float]] = defaultdict(dict)
        self.global_metrics: Dict[str, float] = {}
        
        # Background tasks
        self.monitoring_task: Optional[asyncio.Task] = None
        self.optimization_task: Optional[asyncio.Task] = None
        self.is_running = False
        
        # Threading
        self._lock = threading.RLock()
        
        # Configure logging
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger("GlobalDeploymentOrchestrator")
        
        # Initialize default region configurations
        self._initialize_default_regions()
    
    def _initialize_default_regions(self):
        """Initialize default region configurations"""
        for region in DeploymentRegion:
            self.region_configs[region] = RegionConfig(region=region)
    
    async def deploy_global(self, target: DeploymentTarget) -> Dict[str, str]:
        """Deploy application globally across specified regions"""
        deployment_id = f"deploy_{target.application}_{target.version}_{int(time.time())}"
        
        self.logger.info(f"Starting global deployment: {deployment_id}")
        
        # Validate compliance
        compliance_result = self.compliance_manager.validate_deployment_compliance(
            target, {"user_data", "analytics_data"}
        )
        
        if not compliance_result["compliant"]:
            raise RuntimeError(f"Deployment compliance validation failed: {compliance_result['violations']}")
        
        # Create deployment instances for each region
        deployment_instances = {}
        
        for region in target.regions:
            instance_id = f"{deployment_id}_{region.value}"
            
            instance = DeploymentInstance(
                deployment_id=instance_id,
                target=target,
                region=region,
                status=DeploymentStatus.PENDING,
                created_at=time.time(),
                updated_at=time.time()
            )
            
            deployment_instances[region.value] = instance_id
            
            with self._lock:
                self.active_deployments[instance_id] = instance
        
        # Execute deployment strategy
        if target.strategy == DeploymentStrategy.BLUE_GREEN:
            await self._execute_blue_green_deployment(target, deployment_instances)
        elif target.strategy == DeploymentStrategy.CANARY:
            await self._execute_canary_deployment(target, deployment_instances)
        elif target.strategy == DeploymentStrategy.ROLLING:
            await self._execute_rolling_deployment(target, deployment_instances)
        elif target.strategy == DeploymentStrategy.AUTONOMOUS_ADAPTIVE:
            await self._execute_autonomous_deployment(target, deployment_instances)
        else:
            await self._execute_standard_deployment(target, deployment_instances)
        
        self.logger.info(f"Global deployment completed: {deployment_id}")
        return deployment_instances
    
    async def _execute_blue_green_deployment(self, 
                                           target: DeploymentTarget,
                                           instances: Dict[str, str]):
        """Execute blue-green deployment strategy"""
        self.logger.info("Executing blue-green deployment")
        
        # Deploy to "green" environment
        for region_name, instance_id in instances.items():
            await self._deploy_to_region(instance_id, "green")
        
        # Validate green environment
        all_healthy = await self._validate_deployment_health(list(instances.values()))
        
        if all_healthy:
            # Switch traffic to green
            for instance_id in instances.values():
                await self._switch_traffic(instance_id, 100.0)
            
            # Cleanup blue environment
            await asyncio.sleep(300)  # Wait 5 minutes
            for instance_id in instances.values():
                await self._cleanup_old_environment(instance_id, "blue")
        else:
            # Rollback
            await self._rollback_deployment(list(instances.values()))
    
    async def _execute_canary_deployment(self, 
                                       target: DeploymentTarget,
                                       instances: Dict[str, str]):
        """Execute canary deployment strategy"""
        self.logger.info("Executing canary deployment")
        
        # Start with small percentage
        canary_percentages = [5, 10, 25, 50, 100]
        
        for percentage in canary_percentages:
            self.logger.info(f"Deploying canary at {percentage}% traffic")
            
            # Deploy/update canary instances
            for instance_id in instances.values():
                await self._deploy_to_region(instance_id, "canary", percentage)
            
            # Monitor for issues
            await asyncio.sleep(300)  # 5 minutes monitoring
            
            # Check health metrics
            health_check = await self._validate_deployment_health(list(instances.values()))
            metrics_check = await self._validate_deployment_metrics(list(instances.values()), target)
            
            if not (health_check and metrics_check):
                self.logger.warning(f"Canary deployment failed at {percentage}%")
                await self._rollback_deployment(list(instances.values()))
                return
        
        self.logger.info("Canary deployment completed successfully")
    
    async def _execute_rolling_deployment(self, 
                                        target: DeploymentTarget,
                                        instances: Dict[str, str]):
        """Execute rolling deployment strategy"""
        self.logger.info("Executing rolling deployment")
        
        instance_list = list(instances.values())
        batch_size = max(1, len(instance_list) // 3)  # Deploy in 3 batches
        
        for i in range(0, len(instance_list), batch_size):
            batch = instance_list[i:i + batch_size]
            
            self.logger.info(f"Deploying batch {i // batch_size + 1}: {len(batch)} instances")
            
            # Deploy batch
            for instance_id in batch:
                await self._deploy_to_region(instance_id, "rolling")
            
            # Validate batch
            batch_healthy = await self._validate_deployment_health(batch)
            
            if not batch_healthy:
                self.logger.error("Rolling deployment batch failed")
                await self._rollback_deployment(instance_list)
                return
            
            # Wait before next batch
            if i + batch_size < len(instance_list):
                await asyncio.sleep(180)  # 3 minutes between batches
    
    async def _execute_autonomous_deployment(self, 
                                           target: DeploymentTarget,
                                           instances: Dict[str, str]):
        """Execute autonomous adaptive deployment strategy"""
        self.logger.info("Executing autonomous adaptive deployment")
        
        # Analyze current system state
        system_state = await self._analyze_system_state()
        
        # Choose optimal sub-strategy based on system state
        if system_state["risk_level"] == "low":
            await self._execute_rolling_deployment(target, instances)
        elif system_state["traffic_level"] == "high":
            await self._execute_canary_deployment(target, instances)
        else:
            await self._execute_blue_green_deployment(target, instances)
    
    async def _execute_standard_deployment(self, 
                                         target: DeploymentTarget,
                                         instances: Dict[str, str]):
        """Execute standard deployment (all at once)"""
        self.logger.info("Executing standard deployment")
        
        # Deploy all instances simultaneously
        deployment_tasks = [
            self._deploy_to_region(instance_id, "standard")
            for instance_id in instances.values()
        ]
        
        await asyncio.gather(*deployment_tasks)
        
        # Validate all deployments
        all_healthy = await self._validate_deployment_health(list(instances.values()))
        
        if not all_healthy:
            await self._rollback_deployment(list(instances.values()))
    
    async def _deploy_to_region(self, 
                              instance_id: str, 
                              deployment_type: str, 
                              traffic_percentage: float = 100.0):
        """Deploy to specific region"""
        with self._lock:
            instance = self.active_deployments.get(instance_id)
            if not instance:
                raise RuntimeError(f"Deployment instance not found: {instance_id}")
            
            instance.status = DeploymentStatus.IN_PROGRESS
            instance.updated_at = time.time()
        
        try:
            # Simulate deployment process
            await asyncio.sleep(random.uniform(30, 90))  # 30-90 seconds
            
            # Simulate deployment steps
            steps = [
                "Preparing deployment package",
                "Uploading to region",
                "Configuring infrastructure",
                "Starting services",
                "Running health checks",
                "Configuring load balancer"
            ]
            
            for step in steps:
                instance.logs.append(f"{time.time()}: {step}")
                await asyncio.sleep(random.uniform(5, 15))
            
            # Simulate random deployment success/failure
            success_rate = 0.95  # 95% success rate
            if random.random() < success_rate:
                instance.status = DeploymentStatus.DEPLOYED
                instance.health_status = "healthy"
                instance.logs.append(f"{time.time()}: Deployment completed successfully")
                
                # Update metrics
                instance.metrics.update({
                    "deployment_time": time.time() - instance.created_at,
                    "traffic_percentage": traffic_percentage,
                    "success": True
                })
            else:
                instance.status = DeploymentStatus.FAILED
                instance.health_status = "unhealthy"
                instance.logs.append(f"{time.time()}: Deployment failed")
                
                instance.metrics.update({
                    "deployment_time": time.time() - instance.created_at,
                    "success": False,
                    "error": "Deployment simulation failure"
                })
            
            instance.updated_at = time.time()
            
        except Exception as e:
            instance.status = DeploymentStatus.FAILED
            instance.logs.append(f"{time.time()}: Exception: {str(e)}")
            instance.updated_at = time.time()
            raise
    
    async def _validate_deployment_health(self, instance_ids: List[str]) -> bool:
        """Validate health of deployed instances"""
        healthy_count = 0
        
        for instance_id in instance_ids:
            with self._lock:
                instance = self.active_deployments.get(instance_id)
                if instance and instance.health_status == "healthy":
                    healthy_count += 1
        
        # Require at least 80% healthy
        return healthy_count / len(instance_ids) >= 0.8
    
    async def _validate_deployment_metrics(self, 
                                         instance_ids: List[str],
                                         target: DeploymentTarget) -> bool:
        """Validate deployment metrics against success criteria"""
        # Simulate metrics validation
        # In real implementation, would check actual metrics
        
        for instance_id in instance_ids:
            with self._lock:
                instance = self.active_deployments.get(instance_id)
                if not instance:
                    continue
                
                # Simulate metrics
                simulated_metrics = {
                    "error_rate": random.uniform(0, 0.02),
                    "response_time_p95": random.uniform(50, 300),
                    "availability": random.uniform(0.995, 1.0)
                }
                
                instance.metrics.update(simulated_metrics)
                
                # Check against success criteria
                criteria = target.success_criteria
                if (simulated_metrics["error_rate"] > criteria["error_rate"] or
                    simulated_metrics["response_time_p95"] > criteria["response_time_p95"] or
                    simulated_metrics["availability"] < criteria["availability"]):
                    return False
        
        return True
    
    async def _switch_traffic(self, instance_id: str, percentage: float):
        """Switch traffic to deployment instance"""
        with self._lock:
            instance = self.active_deployments.get(instance_id)
            if instance:
                instance.metrics["traffic_percentage"] = percentage
                instance.logs.append(f"{time.time()}: Traffic switched to {percentage}%")
    
    async def _cleanup_old_environment(self, instance_id: str, environment: str):
        """Cleanup old deployment environment"""
        with self._lock:
            instance = self.active_deployments.get(instance_id)
            if instance:
                instance.logs.append(f"{time.time()}: Cleaned up {environment} environment")
    
    async def _rollback_deployment(self, instance_ids: List[str]):
        """Rollback failed deployment"""
        self.logger.warning("Rolling back deployment")
        
        for instance_id in instance_ids:
            with self._lock:
                instance = self.active_deployments.get(instance_id)
                if instance:
                    instance.status = DeploymentStatus.ROLLING_BACK
                    instance.logs.append(f"{time.time()}: Starting rollback")
            
            # Simulate rollback process
            await asyncio.sleep(random.uniform(15, 45))
            
            with self._lock:
                if instance:
                    instance.status = DeploymentStatus.ROLLED_BACK
                    instance.logs.append(f"{time.time()}: Rollback completed")
                    instance.updated_at = time.time()
    
    async def _analyze_system_state(self) -> Dict[str, str]:
        """Analyze current system state for autonomous decisions"""
        # Simulate system state analysis
        return {
            "risk_level": random.choice(["low", "medium", "high"]),
            "traffic_level": random.choice(["low", "medium", "high"]),
            "error_rate": random.choice(["low", "medium", "high"]),
            "capacity_utilization": random.choice(["low", "medium", "high"])
        }
    
    async def start_monitoring(self):
        """Start global monitoring and optimization"""
        if self.is_running:
            return
        
        self.is_running = True
        self.monitoring_task = asyncio.create_task(self._monitoring_loop())
        self.optimization_task = asyncio.create_task(self._optimization_loop())
        
        self.logger.info("Started global deployment monitoring")
    
    async def stop_monitoring(self):
        """Stop global monitoring"""
        self.is_running = False
        
        if self.monitoring_task:
            self.monitoring_task.cancel()
            try:
                await self.monitoring_task
            except asyncio.CancelledError:
                pass
        
        if self.optimization_task:
            self.optimization_task.cancel()
            try:
                await self.optimization_task
            except asyncio.CancelledError:
                pass
        
        self.logger.info("Stopped global deployment monitoring")
    
    async def _monitoring_loop(self):
        """Background monitoring loop"""
        while self.is_running:
            try:
                await asyncio.sleep(60)  # Monitor every minute
                
                # Update regional metrics
                await self._update_regional_metrics()
                
                # Check deployment health
                await self._check_deployment_health()
                
                # Update load balancer weights
                self.load_balancer.update_traffic_weights(self.regional_metrics)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                self.logger.error(f"Monitoring loop error: {e}")
    
    async def _optimization_loop(self):
        """Background optimization loop"""
        while self.is_running:
            try:
                await asyncio.sleep(300)  # Optimize every 5 minutes
                
                # Optimize edge content distribution
                await self._optimize_edge_distribution()
                
                # Optimize regional capacity
                await self._optimize_regional_capacity()
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                self.logger.error(f"Optimization loop error: {e}")
    
    async def _update_regional_metrics(self):
        """Update metrics for all regions"""
        for region in DeploymentRegion:
            # Simulate regional metrics
            metrics = {
                "avg_latency": random.uniform(50, 200),
                "error_rate": random.uniform(0, 0.02),
                "availability": random.uniform(0.995, 1.0),
                "throughput": random.uniform(1000, 10000),
                "cpu_utilization": random.uniform(0.3, 0.8),
                "memory_utilization": random.uniform(0.4, 0.7)
            }
            
            self.regional_metrics[region] = metrics
    
    async def _check_deployment_health(self):
        """Check health of all active deployments"""
        unhealthy_deployments = []
        
        with self._lock:
            for instance_id, instance in self.active_deployments.items():
                if instance.status == DeploymentStatus.DEPLOYED:
                    # Simulate health check
                    if random.random() < 0.95:  # 95% healthy
                        instance.health_status = "healthy"
                    else:
                        instance.health_status = "unhealthy"
                        unhealthy_deployments.append(instance_id)
        
        # Handle unhealthy deployments
        for instance_id in unhealthy_deployments:
            self.logger.warning(f"Unhealthy deployment detected: {instance_id}")
            # In real implementation, would trigger remediation
    
    async def _optimize_edge_distribution(self):
        """Optimize content distribution across edge locations"""
        # Simulate usage pattern analysis
        usage_patterns = {
            "US-East": 0.3,
            "US-West": 0.25,
            "EU": 0.2,
            "APAC": 0.15,
            "Other": 0.1
        }
        
        # Optimize distribution
        distribution_plan = self.edge_manager.optimize_content_distribution(
            "wasm_models", usage_patterns
        )
        
        self.logger.debug(f"Updated edge distribution plan: {distribution_plan}")
    
    async def _optimize_regional_capacity(self):
        """Optimize capacity allocation across regions"""
        # Analyze regional load and adjust capacity
        for region, metrics in self.regional_metrics.items():
            cpu_util = metrics.get("cpu_utilization", 0.5)
            memory_util = metrics.get("memory_utilization", 0.5)
            
            # Scale up if utilization is high
            if cpu_util > 0.8 or memory_util > 0.8:
                self.logger.info(f"High utilization in {region.value}, recommending scale-up")
            
            # Scale down if utilization is low
            elif cpu_util < 0.3 and memory_util < 0.3:
                self.logger.info(f"Low utilization in {region.value}, recommending scale-down")
    
    def get_global_status(self) -> Dict[str, Any]:
        """Get comprehensive global deployment status"""
        with self._lock:
            active_deployments_by_status = defaultdict(int)
            active_deployments_by_region = defaultdict(int)
            
            for instance in self.active_deployments.values():
                active_deployments_by_status[instance.status.value] += 1
                active_deployments_by_region[instance.region.value] += 1
            
            return {
                "active_deployments": len(self.active_deployments),
                "deployments_by_status": dict(active_deployments_by_status),
                "deployments_by_region": dict(active_deployments_by_region),
                "regional_metrics": {
                    region.value: metrics 
                    for region, metrics in self.regional_metrics.items()
                },
                "global_health": self._calculate_global_health(),
                "edge_locations": len(self.edge_manager.edge_locations),
                "compliance_status": "compliant",  # Simplified
                "monitoring_active": self.is_running
            }
    
    def _calculate_global_health(self) -> str:
        """Calculate overall global health score"""
        if not self.regional_metrics:
            return "unknown"
        
        # Calculate average availability across all regions
        avg_availability = sum(
            metrics.get("availability", 0.99) 
            for metrics in self.regional_metrics.values()
        ) / len(self.regional_metrics)
        
        if avg_availability >= 0.999:
            return "excellent"
        elif avg_availability >= 0.99:
            return "good"
        elif avg_availability >= 0.95:
            return "fair"
        else:
            return "poor"

# Global deployment orchestrator instance
_global_deployment_orchestrator: Optional[GlobalDeploymentOrchestrator] = None

def get_global_deployment_orchestrator() -> GlobalDeploymentOrchestrator:
    """Get global deployment orchestrator instance"""
    global _global_deployment_orchestrator
    if _global_deployment_orchestrator is None:
        _global_deployment_orchestrator = GlobalDeploymentOrchestrator()
    return _global_deployment_orchestrator

async def deploy_globally(application: str,
                         version: str,
                         regions: List[DeploymentRegion],
                         strategy: DeploymentStrategy = DeploymentStrategy.AUTONOMOUS_ADAPTIVE) -> Dict[str, str]:
    """Deploy application globally"""
    orchestrator = get_global_deployment_orchestrator()
    
    target = DeploymentTarget(
        application=application,
        version=version,
        regions=regions,
        strategy=strategy
    )
    
    return await orchestrator.deploy_global(target)